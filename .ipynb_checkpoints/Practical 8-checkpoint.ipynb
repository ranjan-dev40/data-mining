{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7125826a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3416563f",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80719b2",
   "metadata": {},
   "source": [
    "Machine Learning algorithms are completely dependent on data because it is the most crucial aspect that makes model training possible. On the other hand, if we won’t be able to make sense out of that data, before feeding it to ML algorithms, a machine will be useless. In simple words, we always need to feed right data i.e. the data in correct scale, format and containing meaningful features, for the problem we want machine to solve.<br>\n",
    "\n",
    "This makes data preparation the most important step in ML process. Data preparation may be defined as the procedure that makes our dataset more appropriate for ML process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef1d5c",
   "metadata": {},
   "source": [
    "## Data Pre-processing Techniques\n",
    "We have the following data preprocessing techniques that can be applied on data set to produce data for ML algorithms −\n",
    "\n",
    "Scaling\n",
    "Most probably our dataset comprises of the attributes with varying scale, but we cannot provide such data to ML algorithm hence it requires rescaling. Data rescaling makes sure that attributes are at same scale. Generally, attributes are rescaled into the range of 0 and 1. ML algorithms like gradient descent and k-Nearest Neighbors requires scaled data. We can rescale the data with the help of MinMaxScaler class of scikit-learn Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a34e8d",
   "metadata": {},
   "source": [
    "Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab663512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn import preprocessing\n",
    "path = r'pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(path, names=names)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54582903",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16f05f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rescaled = data_scaler.fit_transform(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28866ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled data:\n",
      " [[0.4 0.7 0.6 0.4 0.  0.5 0.2 0.5 1. ]\n",
      " [0.1 0.4 0.5 0.3 0.  0.4 0.1 0.2 0. ]\n",
      " [0.5 0.9 0.5 0.  0.  0.3 0.3 0.2 1. ]\n",
      " [0.1 0.4 0.5 0.2 0.1 0.4 0.  0.  0. ]\n",
      " [0.  0.7 0.3 0.4 0.2 0.6 0.9 0.2 1. ]\n",
      " [0.3 0.6 0.6 0.  0.  0.4 0.1 0.2 0. ]\n",
      " [0.2 0.4 0.4 0.3 0.1 0.5 0.1 0.1 1. ]\n",
      " [0.6 0.6 0.  0.  0.  0.5 0.  0.1 0. ]\n",
      " [0.1 1.  0.6 0.5 0.6 0.5 0.  0.5 1. ]\n",
      " [0.5 0.6 0.8 0.  0.  0.  0.1 0.6 1. ]]\n"
     ]
    }
   ],
   "source": [
    "set_printoptions(precision=1)\n",
    "print (\"\\nScaled data:\\n\", data_rescaled[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fd0f2",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "Another useful data preprocessing technique is Normalization. This is used to rescale each row of data to have a length of 1. It is mainly useful in Sparse dataset where we have lots of zeros. We can rescale the data with the help of Normalizer class of scikit-learn Python library.\n",
    "\n",
    "### Types of Normalization\n",
    "In machine learning, there are two types of normalization preprocessing techniques as follows −\n",
    "\n",
    "### L1 Normalization\n",
    "It may be defined as the normalization technique that modifies the dataset values in a way that in each row the sum of the absolute values will always be up to 1. It is also called Least Absolute Deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50657c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array=dataframe.values\n",
    "from sklearn.preprocessing import Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dc80443",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_normalizer = Normalizer(norm='l1').fit(array)\n",
    "Data_normalized = Data_normalizer.transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c96d3317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized data:\n",
      " [[0.02 0.43 0.21 0.1  0.   0.1  0.   0.14 0.  ]\n",
      " [0.   0.36 0.28 0.12 0.   0.11 0.   0.13 0.  ]\n",
      " [0.03 0.59 0.21 0.   0.   0.07 0.   0.1  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "set_printoptions(precision=2)\n",
    "print (\"\\nNormalized data:\\n\", Data_normalized [0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124b503",
   "metadata": {},
   "source": [
    "## L2 Normalization\n",
    "It may be defined as the normalization technique that modifies the dataset values in a way that in each row the sum of the squares will always be up to 1. It is also called least squares.\n",
    "\n",
    "**Example**\n",
    "\n",
    "In this example, we use L2 Normalization technique to normalize the data of Pima Indians Diabetes dataset which we used earlier. First, the CSV data will be loaded (as done in previous chapters) and then with the help of Normalizer class it will be normalized.\n",
    "\n",
    "The first few lines of following script are same as we have written in previous chapters while loading CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31017852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized data:\n",
      " [[0.03 0.83 0.4  0.2  0.   0.19 0.   0.28 0.01]\n",
      " [0.01 0.72 0.56 0.24 0.   0.22 0.   0.26 0.  ]\n",
      " [0.04 0.92 0.32 0.   0.   0.12 0.   0.16 0.01]]\n"
     ]
    }
   ],
   "source": [
    "Data_normalizer = Normalizer(norm='l2').fit(array)\n",
    "Data_normalized = Data_normalizer.transform(array)\n",
    "set_printoptions(precision=2)\n",
    "print (\"\\nNormalized data:\\n\", Data_normalized [0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d1d4a",
   "metadata": {},
   "source": [
    "## Binarization\n",
    "As the name suggests, this is the technique with the help of which we can make our data binary. We can use a binary threshold for making our data binary. The values above that threshold value will be converted to 1 and below that threshold will be converted to 0. For example, if we choose threshold value = 0.5, then the dataset value above it will become 1 and below this will become 0. That is why we can call it binarizing the data or thresholding the data. This technique is useful when we have probabilities in our dataset and want to convert them into crisp values.\n",
    "\n",
    "We can binarize the data with the help of Binarizer class of scikit-learn Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa266764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary data:\n",
      " [[1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=0.5).fit(array)\n",
    "Data_binarized = binarizer.transform(array)\n",
    "print (\"\\nBinary data:\\n\", Data_binarized [0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bfd38b",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "Another useful data preprocessing technique which is basically used to transform the data attributes with a Gaussian distribution. It differs the mean and SD (Standard Deviation) to a standard Gaussian distribution with a mean of 0 and a SD of 1. This technique is useful in ML algorithms like linear regression, logistic regression that assumes a Gaussian distribution in input dataset and produce better results with rescaled data. We can standardize the data (mean = 0 and SD =1) with the help of StandardScaler class of scikit-learn Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99557132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rescaled data:\n",
      " [[ 0.64  0.85  0.15  0.91 -0.69  0.2   0.47  1.43  1.37]\n",
      " [-0.84 -1.12 -0.16  0.53 -0.69 -0.68 -0.37 -0.19 -0.73]\n",
      " [ 1.23  1.94 -0.26 -1.29 -0.69 -1.1   0.6  -0.11  1.37]\n",
      " [-0.84 -1.   -0.16  0.15  0.12 -0.49 -0.92 -1.04 -0.73]\n",
      " [-1.14  0.5  -1.5   0.91  0.77  1.41  5.48 -0.02  1.37]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data_scaler = StandardScaler().fit(array)\n",
    "data_rescaled = data_scaler.transform(array)\n",
    "set_printoptions(precision=2)\n",
    "print (\"\\nRescaled data:\\n\", data_rescaled [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df83ec",
   "metadata": {},
   "source": [
    "## Data Labeling\n",
    "We discussed the importance of good fata for ML algorithms as well as some techniques to pre-process the data before sending it to ML algorithms. One more aspect in this regard is data labeling. It is also very important to send the data to ML algorithms having proper labeling. For example, in case of classification problems, lot of labels in the form of words, numbers etc. are there on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7908400",
   "metadata": {},
   "source": [
    "## What is Label Encoding?\n",
    "Most of the sklearn functions expect that the data with number labels rather than word labels. Hence, we need to convert such labels into number labels. This process is called label encoding. We can perform label encoding of data with the help of LabelEncoder() function of scikit-learn Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9428bd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels = ['green', 'red', 'black']\n",
      "Encoded values = [1, 2, 0]\n",
      "\n",
      "Encoded values = [3, 0, 4, 1]\n",
      "\n",
      "Decoded labels = ['white', 'black', 'yellow', 'green']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "input_labels = ['red','black','red','green','black','yellow','white']\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(input_labels)\n",
    "test_labels = ['green','red','black']\n",
    "encoded_values = encoder.transform(test_labels)\n",
    "print(\"\\nLabels =\", test_labels)\n",
    "print(\"Encoded values =\", list(encoded_values))\n",
    "encoded_values = [3,0,4,1]\n",
    "decoded_list = encoder.inverse_transform(encoded_values)\n",
    "print(\"\\nEncoded values =\", encoded_values)\n",
    "print(\"\\nDecoded labels =\", list(decoded_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257cac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
